{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d23abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "from pyhdf.SD import SD, SDC  # Used for MODIS HDF4 files\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2751181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "secure = dict([e.split('=') for e in open('secure.txt', 'r').read().split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e5918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_row_dir = 'modis_rows.txt'\n",
    "rows = [line.strip() for line in open(modis_row_dir, 'r') if line.strip()]\n",
    "download_dir = '/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a0e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_earthdata_session():\n",
    "    session = requests.Session()\n",
    "    session.auth = (secure['username'], secure['password'])\n",
    "    resp = session.get(\"https://urs.earthdata.nasa.gov\", allow_redirects=True)\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Failed to authenticate with Earthdata\")\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84591468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_var_and_wr_csv(file_dir, output_csv_path, original_row):\n",
    "    files = [f for f in os.listdir(file_dir) if f.endswith('.hdf')]\n",
    "\n",
    "    dataset_names = [\n",
    "        'LST_Day_1km', 'QC_Day', 'Day_view_time', 'Day_view_angl',\n",
    "        'LST_Night_1km', 'QC_Night', 'Night_view_time', 'Night_view_angl',\n",
    "        'Emis_31', 'Emis_32', 'Clear_sky_days', 'Clear_sky_nights'\n",
    "    ]\n",
    "\n",
    "    # Create header names for min, max, mean of each dataset\n",
    "    stat_fields = []\n",
    "    for name in dataset_names:\n",
    "        stat_fields.extend([\n",
    "            f\"{name.lower()}_min\",\n",
    "            f\"{name.lower()}_max\",\n",
    "            f\"{name.lower()}_mean\"\n",
    "        ])\n",
    "\n",
    "    headers = ['granule_id', 'original_row', 'product', 'location', 'split', 'granuleSize'] + stat_fields\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "\n",
    "    with open(output_csv_path, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "        if os.stat(output_csv_path).st_size == 0:\n",
    "            csvwriter.writeheader()\n",
    "\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(file_dir, file_name)\n",
    "            row_data = {\n",
    "                'granule_id': file_name,\n",
    "                'original_row': original_row,\n",
    "                'product': 'modis',\n",
    "                'location': 'northeast',\n",
    "                'split': 'train',\n",
    "                'granuleSize': os.path.getsize(file_path),\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                hdf = SD(file_path, SDC.READ)\n",
    "\n",
    "                for dataset in dataset_names:\n",
    "                    try:\n",
    "                        data = hdf.select(dataset)[:]\n",
    "                        data = np.where(data == 0, np.nan, data)  # Mask zero if needed\n",
    "\n",
    "                        row_data[f\"{dataset.lower()}_min\"] = np.nanmin(data)\n",
    "                        row_data[f\"{dataset.lower()}_max\"] = np.nanmax(data)\n",
    "                        row_data[f\"{dataset.lower()}_mean\"] = np.nanmean(data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Couldn't process {dataset} in {file_name}: {e}\")\n",
    "                        row_data[f\"{dataset.lower()}_min\"] = \"NA\"\n",
    "                        row_data[f\"{dataset.lower()}_max\"] = \"NA\"\n",
    "                        row_data[f\"{dataset.lower()}_mean\"] = \"NA\"\n",
    "\n",
    "                csvwriter.writerow(row_data)\n",
    "                print(f\"Written: {file_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07560b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def os_remove(tmp_dir=download_dir):\n",
    "    files = [f for f in os.listdir(tmp_dir) if f.endswith('.hdf')]\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(tmp_dir, filename)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Successfully deleted: {filename}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{filename} does not exist or was already deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFileMODIS(row_txt_path, download_dir='C:/tmp/', output_csv_path='C:/oqg_proj1/data_tg/modis_features.csv'):\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    with open(row_txt_path, 'r') as f:\n",
    "        urls = f.read().strip().splitlines()\n",
    "\n",
    "    session = get_earthdata_session()\n",
    "    total_files = len(urls)\n",
    "    times = []\n",
    "\n",
    "    for i, row in enumerate(urls):\n",
    "        try:\n",
    "            outfile = os.path.basename(row)\n",
    "            outfile_path = os.path.join(download_dir, outfile)\n",
    "            print(f\"\\n[{i + 1}/{total_files}] Downloading {outfile}...\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            with session.get(row, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(outfile_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                        f.write(chunk)\n",
    "\n",
    "            print(f\"Downloaded {outfile}\")\n",
    "            extract_var_and_wr_csv(download_dir, output_csv_path, row)\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed = end_time - start_time\n",
    "            times.append(elapsed)\n",
    "\n",
    "            avg_time = np.mean(times)\n",
    "            remaining = avg_time * (total_files - (i + 1))\n",
    "            print(f\"Done {i + 1}/{total_files} | Time: {elapsed:.2f}s | Est. remaining: {remaining:.1f}s ({remaining / 60:.1f} min)\")\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error downloading {row}: {e}\")\n",
    "        finally:\n",
    "            os_remove(download_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de67b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5785] Downloading MOD11A2.A2025113.h13v04.061.2025125151119.hdf...\n",
      "Downloaded MOD11A2.A2025113.h13v04.061.2025125151119.hdf\n",
      "Written: MOD11A2.A2025057.h11v04.061.2025066040453.hdf\n",
      "Written: MOD11A2.A2025057.h11v05.061.2025066040222.hdf\n",
      "Written: MOD11A2.A2025089.h11v04.061.2025098211843.hdf\n",
      "Written: MOD11A2.A2025097.h11v04.061.2025106042553.hdf\n",
      "Written: MOD11A2.A2025097.h11v05.061.2025106042015.hdf\n",
      "Written: MOD11A2.A2025097.h12v04.061.2025106043036.hdf\n",
      "Written: MOD11A2.A2025097.h12v05.061.2025106042807.hdf\n",
      "Written: MOD11A2.A2025097.h13v04.061.2025106042813.hdf\n",
      "Written: MOD11A2.A2025105.h11v04.061.2025114042627.hdf\n",
      "Written: MOD11A2.A2025105.h11v05.061.2025114041528.hdf\n",
      "Written: MOD11A2.A2025105.h12v04.061.2025114041743.hdf\n",
      "Successfully deleted: MOD11A2.A2025057.h11v04.061.2025066040453.hdf\n",
      "Successfully deleted: MOD11A2.A2025057.h11v05.061.2025066040222.hdf\n",
      "Successfully deleted: MOD11A2.A2025089.h11v04.061.2025098211843.hdf\n",
      "Successfully deleted: MOD11A2.A2025097.h11v04.061.2025106042553.hdf\n",
      "Successfully deleted: MOD11A2.A2025097.h11v05.061.2025106042015.hdf\n",
      "Successfully deleted: MOD11A2.A2025097.h12v04.061.2025106043036.hdf\n",
      "Successfully deleted: MOD11A2.A2025097.h12v05.061.2025106042807.hdf\n",
      "Successfully deleted: MOD11A2.A2025097.h13v04.061.2025106042813.hdf\n",
      "Successfully deleted: MOD11A2.A2025105.h11v04.061.2025114042627.hdf\n",
      "Successfully deleted: MOD11A2.A2025105.h11v05.061.2025114041528.hdf\n",
      "Successfully deleted: MOD11A2.A2025105.h12v04.061.2025114041743.hdf\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:/tmp/MOD11A2.A2025105.h12v05.061.2025114043048.hdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m, in \u001b[0;36mloadFileMODIS\u001b[1;34m(row_txt_path, download_dir, output_csv_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m extract_var_and_wr_csv(download_dir, output_csv_path, row)\n\u001b[0;32m     28\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[6], line 49\u001b[0m, in \u001b[0;36mextract_var_and_wr_csv\u001b[1;34m(file_dir, output_csv_path, original_row)\u001b[0m\n\u001b[0;32m     48\u001b[0m     row_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(data)\n\u001b[1;32m---> 49\u001b[0m     row_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmean(data)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1046\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   1044\u001b[0m cnt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m~\u001b[39mmask, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   1045\u001b[0m              where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m-> 1046\u001b[0m tot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   1047\u001b[0m              where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[0;32m   1048\u001b[0m avg \u001b[38;5;241m=\u001b[39m _divide_by_count(tot, cnt, out\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   2314\u001b[0m                       initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     loadFileMODIS(modis_row_dir)\n",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m, in \u001b[0;36mloadFileMODIS\u001b[1;34m(row_txt_path, download_dir, output_csv_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     os_remove(download_dir)\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mos_remove\u001b[1;34m(tmp_dir)\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_dir, filename)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(file_path)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully deleted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:/tmp/MOD11A2.A2025105.h12v05.061.2025114043048.hdf'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    loadFileMODIS(modis_row_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386822fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
